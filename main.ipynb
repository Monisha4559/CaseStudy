{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit scikit-learn pillow matplotlib pandas seaborn joblib pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laAqqpQC4iBz",
        "outputId": "dc57be06-7d6f-4f83-a2aa-21ae7b6d70ef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.50.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.5.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Downloading pyngrok-7.4.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_GKpcZy4QG5",
        "outputId": "7ac5316d-3f1d-4948-eae2-24df604b2d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing streamlit_ml_pipeline_pca.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile streamlit_ml_pipeline_pca.py\n",
        "# ðŸ‘‡ Paste the entire Streamlit code I gave you here\n",
        "import streamlit as st\n",
        "from pathlib import Path\n",
        "import zipfile, shutil, os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "\n",
        "st.set_page_config(page_title=\"Currency ML Pipeline + PCA\", layout=\"wide\")\n",
        "st.title(\"ML Pipeline with PCA for Currency Dataset\")\n",
        "\n",
        "# -------------------- Utilities --------------------\n",
        "def extract_if_zip(path: Path):\n",
        "    \"\"\"Extract zip if needed and return dataset folder\"\"\"\n",
        "    if path.suffix == \".zip\":\n",
        "        extract_dir = Path(\"dataset_extracted\")\n",
        "        if extract_dir.exists():\n",
        "            shutil.rmtree(extract_dir)\n",
        "        with zipfile.ZipFile(path, \"r\") as zf:\n",
        "            zf.extractall(extract_dir)\n",
        "        # handle possible nested folder\n",
        "        subdirs = [p for p in extract_dir.iterdir() if p.is_dir()]\n",
        "        if len(subdirs) == 1 and any(f.is_dir() for f in subdirs[0].iterdir()):\n",
        "            return subdirs[0]\n",
        "        return extract_dir\n",
        "    return path\n",
        "\n",
        "def load_image_paths(data_dir: Path):\n",
        "    \"\"\"Recursively collect image paths\"\"\"\n",
        "    X_paths, y = [], []\n",
        "    for f in data_dir.rglob(\"*\"):\n",
        "        if f.suffix.lower() in (\".jpg\", \".jpeg\", \".png\"):\n",
        "            X_paths.append(f)\n",
        "            y.append(f.parent.name)\n",
        "    return X_paths, np.array(y)\n",
        "\n",
        "def image_to_feature(path: Path, size=(64,32)):\n",
        "    try:\n",
        "        img = Image.open(path).convert('L').resize(size)\n",
        "        arr = np.asarray(img, dtype=np.float32) / 255.0\n",
        "        return arr.flatten()\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Failed: {path}, {e}\")\n",
        "        return None\n",
        "\n",
        "# -------------------- Sidebar: Dataset --------------------\n",
        "st.sidebar.header(\"Dataset\")\n",
        "local_path = st.sidebar.text_input(\"Path to dataset folder or ZIP\", \"demo_currency_dataset.zip\")\n",
        "DATA_DIR = Path(local_path)\n",
        "\n",
        "if not DATA_DIR.exists():\n",
        "    st.error(f\"Path not found: {DATA_DIR}\")\n",
        "    st.stop()\n",
        "\n",
        "DATA_DIR = extract_if_zip(DATA_DIR)\n",
        "\n",
        "X_paths, y = load_image_paths(DATA_DIR)\n",
        "if len(X_paths) == 0:\n",
        "    st.error(\"No images found in dataset\")\n",
        "    st.stop()\n",
        "\n",
        "st.sidebar.success(f\"Found {len(np.unique(y))} classes, {len(y)} images\")\n",
        "\n",
        "# -------------------- Feature Extraction --------------------\n",
        "st.header(\"1) Feature Extraction\")\n",
        "resize_w = st.number_input(\"Resize width\", value=64, min_value=8)\n",
        "resize_h = st.number_input(\"Resize height\", value=32, min_value=8)\n",
        "feature_size = (resize_w, resize_h)\n",
        "\n",
        "progress = st.progress(0)\n",
        "features, labels = [], []\n",
        "for i, p in enumerate(X_paths):\n",
        "    vec = image_to_feature(p, size=feature_size)\n",
        "    if vec is not None:\n",
        "        features.append(vec)\n",
        "        labels.append(y[i])\n",
        "    progress.progress(int((i+1)/len(X_paths)*100))\n",
        "\n",
        "X = np.vstack(features)\n",
        "y = np.array(labels)\n",
        "st.write(f\"Extracted features shape: {X.shape}\")\n",
        "\n",
        "# -------------------- Train/Test Split --------------------\n",
        "st.header(\"2) Train / Test Split\")\n",
        "test_size = st.slider(\"Test size\", 0.1, 0.5, 0.2)\n",
        "random_state = st.number_input(\"Random state\", value=42, min_value=0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=test_size, stratify=y, random_state=int(random_state)\n",
        ")\n",
        "st.write(f\"Train: {X_train.shape[0]}, Test: {X_test.shape[0]}\")\n",
        "\n",
        "# -------------------- Pipeline --------------------\n",
        "st.header(\"3) Pipeline & Model\")\n",
        "pca_components = st.number_input(\"PCA components\", min_value=2, max_value=min(X.shape[1],200), value=50)\n",
        "classifier_name = st.selectbox(\"Classifier\", [\"LogisticRegression\", \"SVC\", \"RandomForest\"])\n",
        "\n",
        "if classifier_name == \"LogisticRegression\":\n",
        "    clf = LogisticRegression(max_iter=1000)\n",
        "elif classifier_name == \"SVC\":\n",
        "    clf = SVC(probability=True)\n",
        "else:\n",
        "    clf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"pca\", PCA(n_components=int(pca_components))),\n",
        "    (\"clf\", clf)\n",
        "])\n",
        "\n",
        "if st.button(\"Train model\"):\n",
        "    with st.spinner(\"Training...\"):\n",
        "        pipeline.fit(X_train, y_train)\n",
        "    st.success(\"Training complete\")\n",
        "\n",
        "    # Evaluation\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    st.metric(\"Test Accuracy\", f\"{acc:.4f}\")\n",
        "\n",
        "    st.subheader(\"Classification Report\")\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    st.dataframe(pd.DataFrame(report).T)\n",
        "\n",
        "    st.subheader(\"Confusion Matrix\")\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=np.unique(y))\n",
        "    fig, ax = plt.subplots(figsize=(6,4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=np.unique(y), yticklabels=np.unique(y), ax=ax)\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    st.subheader(\"Cross-validation (5-fold)\")\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=int(random_state))\n",
        "    scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')\n",
        "    st.write(scores)\n",
        "    st.write(f\"Mean: {scores.mean():.4f}, Std: {scores.std():.4f}\")\n",
        "\n",
        "    st.subheader(\"ROC Curves\")\n",
        "    classes = np.unique(y)\n",
        "    y_test_bin = label_binarize(y_test, classes=classes)\n",
        "    try:\n",
        "        y_score = pipeline.predict_proba(X_test)\n",
        "    except:\n",
        "        try:\n",
        "            y_score = pipeline.decision_function(X_test)\n",
        "        except:\n",
        "            y_score = None\n",
        "    if y_score is not None and y_test_bin.shape[1] > 1:\n",
        "        fig2, ax2 = plt.subplots(figsize=(6,5))\n",
        "        for i, cls in enumerate(classes):\n",
        "            fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            ax2.plot(fpr, tpr, label=f\"{cls} (AUC={roc_auc:.2f})\")\n",
        "        ax2.plot([0,1],[0,1],'k--')\n",
        "        ax2.legend()\n",
        "        st.pyplot(fig2)\n",
        "\n",
        "    # Save pipeline\n",
        "    joblib.dump(pipeline, \"trained_pipeline.joblib\")\n",
        "    with open(\"trained_pipeline.joblib\", \"rb\") as f:\n",
        "        st.download_button(\"Download trained pipeline\", f, file_name=\"trained_pipeline.joblib\")\n",
        "\n",
        "# -------------------- PCA Scatter --------------------\n",
        "st.header(\"4) PCA (2D Projection)\")\n",
        "pca2 = PCA(n_components=2)\n",
        "proj = pca2.fit_transform(StandardScaler().fit_transform(X))\n",
        "df = pd.DataFrame(dict(x=proj[:,0], y=proj[:,1], label=y))\n",
        "fig3, ax3 = plt.subplots(figsize=(7,5))\n",
        "for lbl in df['label'].unique():\n",
        "    subset = df[df['label']==lbl]\n",
        "    ax3.scatter(subset['x'], subset['y'], label=lbl, alpha=0.7)\n",
        "ax3.legend()\n",
        "st.pyplot(fig3)\n",
        "\n",
        "\n"
      ]
    }
  ]
}